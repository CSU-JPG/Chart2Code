# This script reads a JSON file to get image paths, generates Python code for the images using the VolcEngine Ark API,
# and saves the results to a specified directory while logging the process.
# It has been refactored to be compatible with a standardized shell runner.

import os
import torch
from PIL import Image
from tqdm import tqdm
import re
import shutil
import csv
import argparse
import json
import base64
from volcenginesdkarkruntime import Ark
from dotenv import load_dotenv

# ===================================================================================
# Model Configuration
# ===================================================================================
# 1. API Model ID
API_MODEL_ID = 'doubao-1-5-thinking-vision-pro-250428'

# 2. Load environment variables for API URL and Key
load_dotenv()
ARK_BASE_URL = os.getenv('ARK_BASE_URL', 'https://ark.cn-beijing.volces.com/api/v3')
# The API key will be read from the ARK_API_KEY environment variable.
# ===================================================================================


# --- Global Variables ---
# The API client will be initialized in the main function
client = None

# --- Prompt Template (Do not change) ---
PROMPT_TEMPLATE = """You are a Python developer proficient in data visualization, with expertise in using libraries such as Matplotlib, NetworkX, Seaborn, and others.I have a plot generated by Python code, but I don't have the corresponding code that generated this plot. Your task is to generate the Python code that can perfectly reproduce the picture based on the image I provide.

Here are the requirements for the task:
1. **Data Extraction**: Extract the actual data from the provided image. Based on the visual features of the plot, you must infer the data and recreate the plot.
2. **Recreate the Image**: Generate the Matplotlib code that reproduces the image exactly as it appears, including all elements such as:
   - Plot type (scatter, line, bar, etc.)
   - Axis labels and titles
   - Colors, markers, line styles, and other visual styles
   - Any legends, annotations, or gridlines present in the image
3. **Self-contained Code**: The Python code should be complete, executable, and self-contained. It should not require any external data files or variables not already present in the code.
Your objective is to extract the any necessary details from the image and generate a Python script that accurately reproduces the plot.

Now, please generate the Python code to reproduce the picture below.
The output format must be strictly as follows:

```python
# Your Python code here to reproduce the image.
```"""

# --- Inference Parameters (Do not change) ---
INFERENCE_PARAMS = {
    "temperature": 0.1,
    "top_p": 0.9,
    "max_tokens": 8192,
    "thinking": {
        "type": "disabled"  # Do not use deep thinking capabilities
    }
}


# --- Helper function to encode images ---
def encode_image_to_base64(image_path: str) -> str:
    """Encodes an image to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        tqdm.write(f"  - Error: Failed to encode image {os.path.basename(image_path)} -> {e}")
        return None

# --- Code Extraction Function (Do not change) ---
def extract_python_code(raw_text: str) -> str:
    """
    Extracts Python code from a markdown-formatted string.
    Returns an empty string if no code block is found.
    """
    match = re.search(r"```python\s*\n(.*?)\n```", raw_text, re.DOTALL)
    if match:
        return match.group(1).strip()

    match = re.search(r"```\s*\n(.*?)\n```", raw_text, re.DOTALL)
    if match:
        return match.group(1).strip()

    return ""

# --- Core Inference Function (Adapted for Ark API) ---
def generate_code_for_image(image_path: str) -> str:
    """Generates code for a given image using the VolcEngine Ark API."""
    try:
        image_base64 = encode_image_to_base64(image_path)
        if not image_base64:
            return None # Error message was already printed by the encoder

        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": PROMPT_TEMPLATE},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_base64}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ]

        response = client.chat.completions.create(
            model=API_MODEL_ID,
            messages=messages,
            **INFERENCE_PARAMS
        )
        
        if response.choices and response.choices[0].message.content:
             return response.choices[0].message.content.strip()
        else:
             return None

    except Exception as e:
        tqdm.write(f"  - Error: Exception caught inside the API inference function -> {os.path.basename(image_path)} | Error: {e}")
        return None

# --- Batch Processing Main Flow ---
def main():
    # --- Standardized command-line argument parsing ---
    parser = argparse.ArgumentParser(description=f"Generate Python code for images using the {API_MODEL_ID} API.")
    # The --load_source argument is included for compatibility with the shell runner but is not used in this API-based script.
    parser.add_argument('--load_source', type=str, choices=['local', 'hub'], default='hub',
                        help="Select model loading source (accepted for compatibility, but not used).")
    parser.add_argument('--json_path', type=str, required=True, help="Path to the input JSON file containing image paths.")
    parser.add_argument('--output_dir', type=str, required=True, help="Directory to save the generated Python code.")
    parser.add_argument('--log_path', type=str, required=True, help="Path to save the CSV log file.")
    args = parser.parse_args()

    # --- API Client Initialization ---
    global client
    print(f"Initializing VolcEngine Ark API client for model '{API_MODEL_ID}'...")
    try:
        # The Ark client automatically reads ARK_API_KEY from environment variables
        client = Ark(base_url=ARK_BASE_URL)
        # A simple check to ensure the client is configured
        if not os.getenv('ARK_API_KEY'):
             raise ValueError("ARK_API_KEY is not configured in the .env file.")
        print("✅ API client configured successfully!")
    except Exception as e:
        print(f"❌ VolcEngine Ark API client configuration failed: {e}")
        exit(1)


    # --- Configure paths from command-line arguments ---
    JSON_FILE_PATH = args.json_path
    GENERATED_CODE_DIR = args.output_dir
    LOG_CSV_PATH = args.log_path
    FAILED_FILES_DIR = f"{GENERATED_CODE_DIR}_failed"

    os.makedirs(GENERATED_CODE_DIR, exist_ok=True)
    os.makedirs(FAILED_FILES_DIR, exist_ok=True)

    # --- Read image list from JSON file ---
    try:
        with open(JSON_FILE_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)

        script_dir = os.path.dirname(os.path.abspath(__file__))
        data_dir = os.path.abspath(os.path.join(script_dir, '..', '..', '..', 'data'))

        image_files = []
        for item in data:
            if "input image" in item and item["input image"]:
                relative_path = item["input image"]
                full_path = os.path.join(data_dir, relative_path)
                image_files.append(full_path)
    except FileNotFoundError:
        print(f"❌ Error: JSON file not found -> '{JSON_FILE_PATH}'")
        return
    except json.JSONDecodeError:
        print(f"❌ Error: Could not parse JSON file -> '{JSON_FILE_PATH}'")
        return
    except Exception as e:
        print(f"❌ Error: An unknown error occurred while reading the JSON file: {e}")
        return

    if not image_files:
        print(f"❌ Error: No valid 'input image' entries found in the JSON file '{JSON_FILE_PATH}'.")
        return

    total_files = len(image_files)
    print(f"Found {total_files} images in '{os.path.basename(JSON_FILE_PATH)}', starting processing...")

    success_count = 0
    failure_count = 0

    try:
        with open(LOG_CSV_PATH, 'w', newline='', encoding='utf-8') as csvfile:
            csv_writer = csv.writer(csvfile)
            csv_writer.writerow(["Figure Filename", "Status", "Instruction", "Raw Model Output", "Extracted Code"])

            for image_path in tqdm(image_files, desc="Processing progress"):
                if not os.path.exists(image_path):
                    tqdm.write(f"  - Warning: Image file not found, skipping -> {image_path}")
                    csv_writer.writerow([os.path.basename(image_path), "SKIPPED_NOT_FOUND", "N/A", "N/A", "N/A"])
                    continue

                base_name, _ = os.path.splitext(os.path.basename(image_path))
                output_path = os.path.join(GENERATED_CODE_DIR, f"{base_name}.py")
                figure_filename = os.path.basename(image_path)

                if os.path.exists(output_path):
                    tqdm.write(f"  - Skipping: Output file '{output_path}' already exists")
                    csv_writer.writerow([figure_filename, "SKIPPED_EXISTS", PROMPT_TEMPLATE, "N/A", "N/A"])
                    continue

                raw_generated_text = generate_code_for_image(image_path)

                if raw_generated_text:
                    clean_code = extract_python_code(raw_generated_text)

                    if clean_code:
                        with open(output_path, 'w', encoding='utf-8') as f:
                            f.write(clean_code)
                        csv_writer.writerow([figure_filename, "SUCCESS", PROMPT_TEMPLATE, raw_generated_text, clean_code])
                        success_count += 1
                    else:
                        failure_count += 1
                        tqdm.write(f"  - Failure: Failed to extract valid code from model output -> {base_name}")
                        csv_writer.writerow([figure_filename, "FAILURE_EXTRACT", PROMPT_TEMPLATE, raw_generated_text, ""])
                        shutil.copy(image_path, FAILED_FILES_DIR)
                else:
                    failure_count += 1
                    tqdm.write(f"  - Failure: Error occurred during inference -> {base_name}")
                    csv_writer.writerow([figure_filename, "FAILURE_INFERENCE", PROMPT_TEMPLATE, "N/A", "N/A"])
                    try:
                        shutil.copy(image_path, FAILED_FILES_DIR)
                    except Exception as e:
                        tqdm.write(f"  - Critical Error: An error also occurred while copying the failed file: {e}")

    except IOError as e:
        print(f"❌ Critical Error: Could not write to CSV log file '{LOG_CSV_PATH}'. Error: {e}")
    finally:
        print(f"\n--- ✅ Batch processing complete (Model: {API_MODEL_ID}) ---")
        print(f"Detailed log saved to: {LOG_CSV_PATH}")
        print(f"Successfully processed: {success_count} | Failed: {failure_count}")

if __name__ == "__main__":
    main()

